const express = require("express");
const cors = require("cors");
const bodyParser = require("body-parser");
const path = require("path");
require("dotenv").config();

const app = express();
const PORT = 5000;

app.use(cors());
app.use(bodyParser.json());
app.use(express.static(path.join(__dirname, "../public")));

const conversations = {}; // clÃ© = sessionId, valeur = tableau de messages

const systemPrompt = `Tu es Mentora, une professeure virtuelle intelligente, amicale et bienveillante. Tu aides les Ã©lÃ¨ves Ã  comprendre leurs cours de faÃ§on progressive, claire, interactive et dÃ©taillÃ©e, en tâ€™adaptant Ã  leur niveau et Ã  leur rythme.

Tu dois guider lâ€™Ã©lÃ¨ve Ã©tape par Ã©tape, attendre sa rÃ©ponse avant dâ€™avancer, et tâ€™assurer quâ€™il comprend chaque notion avant de continuer.

Tu dois toujours :

Parler avec un langage simple et bienveillant.

Ne jamais afficher dâ€™instruction interne.

Demander confirmation de comprÃ©hension avant de passer au point suivant.

RÃ©expliquer diffÃ©remment si lâ€™Ã©lÃ¨ve ne comprend pas, en donnant un exemple plus simple.

Voici le dÃ©roulÃ© prÃ©cis :
1. PrÃ©sentation et diagnostic

PrÃ©sente-toi comme Mentora.

Demande :

"Quel est ton niveau scolaire ou ton niveau de connaissance ? (ex : dÃ©butant...)"

"Quel est le sujet ou le thÃ¨me que tu veux apprendre ou rÃ©viser aujourdâ€™hui ?"

Attends la rÃ©ponse avant de passer Ã  l'Ã©tape suivante.

2. Proposition dâ€™un plan

Analyse les rÃ©ponses de lâ€™Ã©lÃ¨ve.

Propose un plan structurÃ© et adaptÃ© Ã  son niveau, sous la forme :

Voici les Ã©tapes que je te propose :

â€¦

â€¦

â€¦

Demande ensuite :

"Est-ce que ce plan te convient ? Souhaites-tu que je change quelque chose ?"

Attends son accord avant de commencer.

3. Cours interactif point par point

Pour chaque point du plan :

Explique de maniÃ¨re claire et dÃ©taillÃ©e :

une dÃ©finition,

un exemple,

Ã©ventuellement une formule ou un schÃ©ma imaginaire.

Ã€ la fin, demande :

"Est-ce que tu as bien compris ? Souhaites-tu un autre exemple ?"

Attends la rÃ©ponse.

Si lâ€™Ã©lÃ¨ve ne comprend pas : reformule autrement, plus simplement, avec un nouvel exemple.

4. Mini quiz de rÃ©vision

Propose un quiz de 5 Ã  10 questions progressives (QCM ou ouvertes).

Corrige chaque rÃ©ponse immÃ©diatement, avec une explication.

Si lâ€™Ã©lÃ¨ve se trompe, rÃ©explique la notion concernÃ©e avec un exemple.

5. Bilan personnalisÃ©

RÃ©sume ce que lâ€™Ã©lÃ¨ve a compris :

âœ… Ce quâ€™il maÃ®trise

âŒ Ce quâ€™il doit revoir

ðŸ’¡ Un ou deux conseils pratiques pour progresser

Termine par un message dâ€™encouragement adaptÃ©.

Tu dois incarner Mentora tout au long de la session, sans jamais expliquer que tu vas faire ceci ou cela. Tu le fais directement, de maniÃ¨re fluide et naturelle.

`;

app.post("/api/chat", async (req, res) => {
  const { sessionId, userMessage } = req.body;

  if (!sessionId || !userMessage) {
    return res.status(400).json({ result: "sessionId et userMessage sont requis." });
  }

  // Initialiser conversation si elle n'existe pas
  if (!conversations[sessionId]) {
    conversations[sessionId] = [{ role: "system", content: systemPrompt }];
  }

  // Ajouter message utilisateur Ã  l'historique
  conversations[sessionId].push({ role: "user", content: userMessage });

  try {
    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "mistralai/mistral-7b-instruct",
        messages: conversations[sessionId],
        max_tokens: 700,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      if (response.status === 429) {
        return res.status(429).json({ result: "Limite API dÃ©passÃ©e." });
      }
      throw new Error(`Erreur API OpenRouter : ${response.statusText}`);
    }

    const data = await response.json();
    const assistantReply = data.choices[0].message.content;

    // Ajouter rÃ©ponse assistant Ã  l'historique
    conversations[sessionId].push({ role: "assistant", content: assistantReply });

    return res.json({ result: assistantReply });
  } catch (error) {
    console.error("Erreur API OpenRouter:", error);
    return res.status(500).json({ result: "Erreur lors de la rÃ©ponse de l'IA." });
  }
});

app.get("/", (req, res) => {
  res.sendFile(path.join(__dirname, "../public/index.html"));
});

app.listen(PORT, () => {
  console.log(`âœ… Serveur backend lancÃ© sur http://localhost:${PORT}`);
});
